{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f93ca5",
   "metadata": {},
   "source": [
    "#### Data cleaning plan for loans-repayments dataset\n",
    "\n",
    "1. **Initialize SparkSession**\n",
    "\n",
    "2. **Define loans-repayments schema**\n",
    "\n",
    "3. **Load raw repayments CSV**\n",
    "   - Set `header=True`\n",
    "   - Apply predefined schema\n",
    "\n",
    "4. **Inspect raw DataFrame**\n",
    "   - Show sample rows\n",
    "   - Print schema\n",
    "\n",
    "5. **Add ingestion timestamp** (`ingest_date`)\n",
    "\n",
    "6. **Create temporary view** `\"loan_repayments\"`\n",
    "\n",
    "7. **Data quality checks**\n",
    "   - Total record count\n",
    "   - Count of null `total_principal_received`\n",
    "\n",
    "8. **Drop rows with nulls in critical repayment fields**\n",
    "\n",
    "9. **Recreate temp view**\n",
    "\n",
    "10. **Identify zero-payment anomalies**\n",
    "    - Count `total_payment_received == 0.0`\n",
    "    - Count rows where `total_payment_received == 0.0` AND `total_principal_received != 0.0`\n",
    "    - Show those anomalous rows\n",
    "\n",
    "11. **Fix `total_payment_received` where anomalies exist**\n",
    "\n",
    "12. **Filter out any remaining zero-payment rows**\n",
    "\n",
    "13. **Clean up date fields**\n",
    "    - Replace `0.0` in `last_payment_date` with `null`\n",
    "    - Replace `0.0` in `next_payment_date` with `null`\n",
    "\n",
    "14. **Save cleaned DataFrame**\n",
    "    - Parquet → `/user/itv006277/lendingclubproject/raw/cleaned/loans_repayments_parquet`\n",
    "    - CSV → `/user/itv006277/lendingclubproject/raw/cleaned/loans_repayments_csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8871b",
   "metadata": {},
   "source": [
    "### 1. Initialize SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847c8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass \n",
    "username=getpass.getuser()\n",
    "spark=SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port','0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    config('spark.shuffle.useOldFetchProtocol', 'true'). \\\n",
    "    enableHiveSupport(). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cdd661",
   "metadata": {},
   "source": [
    "### 2. Define loans‑repayments schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d099ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define exact column names and types for repayments data\n",
    "loans_repay_schema = \"\"\"\n",
    "    loan_id string,\n",
    "    total_principal_received float,\n",
    "    total_interest_received float,\n",
    "    total_late_fee_received float,\n",
    "    total_payment_received float,\n",
    "    last_payment_amount float,\n",
    "    last_payment_date string,\n",
    "    next_payment_date string\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c489b",
   "metadata": {},
   "source": [
    "### 3. Load raw repayments CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681bf889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw CSV with header and enforced schema\n",
    "loans_repay_raw_df = (\n",
    "    spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", True)\n",
    "      .schema(loans_repay_schema)\n",
    "      .load(\"/public/trendytech/lendingclubproject/raw/loans_repayments_csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17375f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+\n",
      "|  loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+\n",
      "|141581221|                 1055.81|                 2591.7|                    0.0|               3647.51|             709.23|         Mar-2019|         Apr-2019|\n",
      "|141506948|                 1252.75|                 306.04|                    0.0|               1558.79|             312.63|         Mar-2019|         Apr-2019|\n",
      "|141357400|                  626.37|                 354.96|                    0.0|                981.33|             197.27|         Mar-2019|         Apr-2019|\n",
      "|139445427|                 1118.16|                 297.36|                    0.0|               1415.52|             283.95|         Mar-2019|         Apr-2019|\n",
      "|141407409|                 1169.72|                 3605.3|                    0.0|               4775.02|              964.9|         Mar-2019|         Apr-2019|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Peek at first few rows\n",
    "loans_repay_raw_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd008ab",
   "metadata": {},
   "source": [
    "### 4. Inspect raw DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ccc7b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_id: string (nullable = true)\n",
      " |-- total_principal_received: float (nullable = true)\n",
      " |-- total_interest_received: float (nullable = true)\n",
      " |-- total_late_fee_received: float (nullable = true)\n",
      " |-- total_payment_received: float (nullable = true)\n",
      " |-- last_payment_amount: float (nullable = true)\n",
      " |-- last_payment_date: string (nullable = true)\n",
      " |-- next_payment_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print schema to verify types\n",
    "loans_repay_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a9078a",
   "metadata": {},
   "source": [
    "### 5. Add ingestion timestamp (`ingest_date`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e8fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "|  loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|         ingest_date|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "|141581221|                 1055.81|                 2591.7|                    0.0|               3647.51|             709.23|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|141506948|                 1252.75|                 306.04|                    0.0|               1558.79|             312.63|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|141357400|                  626.37|                 354.96|                    0.0|                981.33|             197.27|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|139445427|                 1118.16|                 297.36|                    0.0|               1415.52|             283.95|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|141407409|                 1169.72|                 3605.3|                    0.0|               4775.02|              964.9|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "# Tag each row with the ingestion time\n",
    "loans_repay_df_ingestd = loans_repay_raw_df.withColumn(\"ingest_date\", current_timestamp())\n",
    "loans_repay_df_ingestd.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77224e5f",
   "metadata": {},
   "source": [
    "### 6. Create temporary view \"loan_repayments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c2d111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_repay_df_ingestd.createOrReplaceTempView(\"loan_repayments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951f386",
   "metadata": {},
   "source": [
    "### 7. Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2198f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2260701|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      69|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Total records\n",
    "spark.sql(\"SELECT COUNT(*) FROM loan_repayments\").show()\n",
    "\n",
    "# How many missing principal?\n",
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "      FROM loan_repayments \n",
    "     WHERE total_principal_received IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7bdcbe",
   "metadata": {},
   "source": [
    "### 8. Drop rows with nulls in critical fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679a65d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After drop: 2260498\n"
     ]
    }
   ],
   "source": [
    "# Define fields that must not be null\n",
    "columns_to_check = [\n",
    "    \"total_principal_received\",\n",
    "    \"total_interest_received\",\n",
    "    \"total_late_fee_received\",\n",
    "    \"total_payment_received\",\n",
    "    \"last_payment_amount\"\n",
    "]\n",
    "\n",
    "# Drop any rows missing one of these\n",
    "loans_repay_filtered_df = loans_repay_df_ingestd.na.drop(subset=columns_to_check)\n",
    "print(\"After drop:\", loans_repay_filtered_df.count())\n",
    "\n",
    "# Refresh SQL view\n",
    "loans_repay_filtered_df.createOrReplaceTempView(\"loan_repayments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f9585",
   "metadata": {},
   "source": [
    "### 9. Identify zero‑payment anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac22411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     995|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count zero-payment rows\n",
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "      FROM loan_repayments \n",
    "     WHERE total_payment_received = 0.0\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d941634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      46|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count those where principal != 0 but payment = 0\n",
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "      FROM loan_repayments \n",
    "     WHERE total_payment_received = 0.0 \n",
    "       AND total_principal_received != 0.0\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e53ab2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "|loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|         ingest_date|\n",
      "+-------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "| 485818|               14640.096|               13388.84|                13000.0|                   0.0|                0.0|              0.0|         Mar-2013|2025-04-29 06:06:...|\n",
      "| 485471|               29620.818|               29134.64|                25000.0|                   0.0|                0.0|              0.0|         Mar-2013|2025-04-29 06:06:...|\n",
      "| 482256|                8735.611|                7479.87|                 8000.0|                   0.0|                0.0|              0.0|         Feb-2011|2025-04-29 06:06:...|\n",
      "| 478160|                   410.0|                 407.36|                    0.0|                   0.0|              143.1|            410.0|             null|2025-04-29 06:06:...|\n",
      "| 476557|                28865.18|               24164.67|                5692.31|                   0.0|            6972.59|         19916.78|         Dec-2010|2025-04-29 06:06:...|\n",
      "+-------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show some examples of these anomalies\n",
    "spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "      FROM loan_repayments \n",
    "     WHERE total_payment_received = 0.0 \n",
    "       AND total_principal_received != 0.0\n",
    "     LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7c74f",
   "metadata": {},
   "source": [
    "### 10. Fix total_payment_received for anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2267f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "|  loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|         ingest_date|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "|141581221|                 1055.81|                 2591.7|                    0.0|               3647.51|             709.23|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|141506948|                 1252.75|                 306.04|                    0.0|               1558.79|             312.63|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|141357400|                  626.37|                 354.96|                    0.0|                981.33|             197.27|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|139445427|                 1118.16|                 297.36|                    0.0|               1415.52|             283.95|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|141407409|                 1169.72|                 3605.3|                    0.0|               4775.02|              964.9|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# Where principal ≠ 0 & payment = 0, recompute payment as principal + interest + late fee\n",
    "loans_payments_fixed_df = loans_repay_filtered_df.withColumn(\n",
    "    \"total_payment_received\",\n",
    "    when(\n",
    "        (col(\"total_principal_received\") != 0.0) &\n",
    "        (col(\"total_payment_received\") == 0.0),\n",
    "        col(\"total_principal_received\") \n",
    "          + col(\"total_interest_received\") \n",
    "          + col(\"total_late_fee_received\")\n",
    "    ).otherwise(col(\"total_payment_received\"))\n",
    ")\n",
    "\n",
    "loans_payments_fixed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905ea957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even after fixing loan_payments there are values 0.0, then we drop those rows\n",
    "loans_payments_fixed2_df = loans_payments_fixed_df.filter(\"total_payment_received != 0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8823cc",
   "metadata": {},
   "source": [
    "### 11. Filter out any remaining zero‑payment rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d26f99ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_payments_fixed2_df.filter(\"last_payment_date = 0.0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d410c83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_payments_fixed2_df.filter(\"next_payment_date =0.0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f882058d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1477"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_payments_fixed2_df.filter(\"last_payment_date is null\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055188a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1344240"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_payments_fixed2_df.filter(\"next_payment_date is null\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ca52229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# For last_payment_date\n",
    "loans_payments_ldate_fixed_df = loans_payments_fixed2_df.withColumn(\n",
    "    \"last_payment_date\",\n",
    "    when(col(\"last_payment_date\") == \"0.0\", None)\n",
    "     .otherwise(col(\"last_payment_date\"))\n",
    ")\n",
    "\n",
    "# For next_payment_date\n",
    "loans_payments_ndate_fixed_df = loans_payments_ldate_fixed_df.withColumn(\n",
    "    \"next_payment_date\",\n",
    "    when(col(\"next_payment_date\") == \"0.0\", None)\n",
    "     .otherwise(col(\"next_payment_date\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309bf72f",
   "metadata": {},
   "source": [
    "### 12. Clean date fields: replace `0.0` with null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e98b5ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "|  loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|         ingest_date|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "|141581221|                 1055.81|                 2591.7|                    0.0|               3647.51|             709.23|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|141506948|                 1252.75|                 306.04|                    0.0|               1558.79|             312.63|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|141357400|                  626.37|                 354.96|                    0.0|                981.33|             197.27|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|139445427|                 1118.16|                 297.36|                    0.0|               1415.52|             283.95|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "|141407409|                 1169.72|                 3605.3|                    0.0|               4775.02|              964.9|         Mar-2019|         Apr-2019|2025-04-29 06:06:...|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# For last_payment_date\n",
    "loans_payments_ldate_fixed_df = loans_payments_fixed2_df.withColumn(\n",
    "    \"last_payment_date\",\n",
    "    when(col(\"last_payment_date\") == \"0.0\", None)\n",
    "     .otherwise(col(\"last_payment_date\"))\n",
    ")\n",
    "\n",
    "# For next_payment_date\n",
    "loans_payments_ndate_fixed_df = loans_payments_ldate_fixed_df.withColumn(\n",
    "    \"next_payment_date\",\n",
    "    when(col(\"next_payment_date\") == \"0.0\", None)\n",
    "     .otherwise(col(\"next_payment_date\"))\n",
    ")\n",
    "\n",
    "loans_payments_ndate_fixed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e10a37",
   "metadata": {},
   "source": [
    "### 13. Save cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f8150a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet (optimized format)\n",
    "loans_payments_ndate_fixed_df.write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"path\", \"/user/itv017499/lendingclubproject/cleaned/loans_repayments_parquet\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
